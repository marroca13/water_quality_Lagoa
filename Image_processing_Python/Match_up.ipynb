{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match-up analysis (Sentinel-2 pixels vs in situ data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import uav\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# NDWI mask filename\n",
    "ndwi_filename = r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\masks\\ndwi.tif'\n",
    "\n",
    "with rasterio.open(ndwi_filename) as src:\n",
    "    is_water = src.read() > 0.1\n",
    "    water_mask_tif = uav.GeoreferenceData(is_water, src.transform)\n",
    "\n",
    "# Tif of one band (ex: 442) for reference\n",
    "with rasterio.open(r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\base_georeference_reduced.tif') as reference:\n",
    "    transform = reference.transform\n",
    "    height, width = reference.read(1).shape\n",
    "    \n",
    "\n",
    "# Function to extract values - NDWI masked\n",
    "def match_points_mask_ndwi(netcdf_path, variables, points, clear_outliers : bool = False, \n",
    "                        kernel_size = 1, method = np.nanmean) -> None:\n",
    "    def __extract_values(data, x_0, y_0, kernel_size, method, clear_outliers = False):\n",
    "        values = [ data[y, x] for y in range(y_0 - kernel_size, y_0 + kernel_size + 1) for x in range(x_0 - kernel_size, x_0 + kernel_size + 1)]\n",
    "        \n",
    "        if clear_outliers:\n",
    "            values = remove_by_zscore(np.array(values))\n",
    "\n",
    "        return float(method(values)), np.count_nonzero(~np.isnan(values))\n",
    "    \n",
    "    matches_by_variable = {variable : [] for variable in variables} | {'x' : points[:, 0], 'y' : points[:, 1]} \\\n",
    "                            |{f'{variable}_no_nans' : [] for variable in variables}\n",
    "\n",
    "\n",
    "    with xr.open_dataset(netcdf_path) as dataset:\n",
    "        xs, ys = np.meshgrid(src.x, src.y)\n",
    "        rows, cols = water_mask_tif.get_row_col_by_lon_lat(xs, ys)\n",
    "        in_shape = water_mask_tif.get_in_shape_mask(rows, cols)\n",
    "        is_water_mask = water_mask_tif.get_data_by_row_col(rows[in_shape], cols[in_shape])[0].reshape((height, width))\n",
    "        \n",
    "        for point in points:\n",
    "            x_index = np.absolute(dataset.x.values - point[0]).argmin()\n",
    "            y_index = np.absolute(dataset.y.values - point[1]).argmin()\n",
    "\n",
    "            for variable in variables:\n",
    "                if variable in dataset:\n",
    "                    data = np.squeeze(dataset[variable])\n",
    "                    data[~is_water_mask] = np.nan\n",
    "\n",
    "                    value, no_nans = __extract_values(data, x_index, y_index, kernel_size, method, clear_outliers)\n",
    "                    matches_by_variable[variable].append(float(value))\n",
    "                    matches_by_variable[f'{variable}_no_nans'].append(int(no_nans))\n",
    "                else:\n",
    "                    matches_by_variable[variable].append(np.nan)\n",
    "                    matches_by_variable[f'{variable}_no_nans'].append(np.nan)\n",
    "\n",
    "    return matches_by_variable\n",
    "\n",
    "# Function to extract values - NDWI masked and deepwater\n",
    "def match_points_mask_ndwi_deepwater(netcdf_path, variables, points, clear_outliers : bool = False, \n",
    "                        kernel_size = 1, method = np.nanmean, mask_deep = True) -> None:\n",
    "    def __extract_values(data, x_0, y_0, kernel_size, method, clear_outliers = False):\n",
    "        values = [ data[y, x] for y in range(y_0 - kernel_size, y_0 + kernel_size + 1) for x in range(x_0 - kernel_size, x_0 + kernel_size + 1)]\n",
    "        \n",
    "        if clear_outliers:\n",
    "            values = remove_by_zscore(np.array(values))\n",
    "\n",
    "        return float(method(values)), np.count_nonzero(~np.isnan(values))\n",
    "    \n",
    "    matches_by_variable = {variable : [] for variable in variables} | {'x' : points[:, 0], 'y' : points[:, 1]} \\\n",
    "                            |{f'{variable}_no_nans' : [] for variable in variables}\n",
    "\n",
    "    with xr.open_dataset(r\"D:\\sentinel2-acolite-prod\\jupyters\\Mar\\masks\\deep_water.nc\") as deep_file:\n",
    "        name = os.path.basename(os.path.dirname(netcdf_path))[:4]\n",
    "        \n",
    "        for var in deep_file:\n",
    "            if name in var:\n",
    "                deep_water_mask = deep_file[var]\n",
    "        \n",
    "    if mask_deep:\n",
    "        deep_water_mask = deep_water_mask\n",
    "    else:\n",
    "        deep_water_mask = ~deep_water_mask\n",
    "\n",
    "    with xr.open_dataset(netcdf_path) as dataset:\n",
    "        xs, ys = np.meshgrid(src.x, src.y)\n",
    "        rows, cols = water_mask_tif.get_row_col_by_lon_lat(xs, ys)\n",
    "        in_shape = water_mask_tif.get_in_shape_mask(rows, cols)\n",
    "        is_water_mask = water_mask_tif.get_data_by_row_col(rows[in_shape], cols[in_shape])[0].reshape((height, width))\n",
    "        \n",
    "        for point in points:\n",
    "            x_index = np.absolute(dataset.x.values - point[0]).argmin()\n",
    "            y_index = np.absolute(dataset.y.values - point[1]).argmin()\n",
    "\n",
    "            for variable in variables:\n",
    "                if variable in dataset:\n",
    "                    data = np.squeeze(dataset[variable])\n",
    "                    data[~is_water_mask] = np.nan\n",
    "                    data[deep_water_mask] = np.nan\n",
    "\n",
    "                    value, no_nans = __extract_values(data, x_index, y_index, kernel_size, method, clear_outliers)\n",
    "                    matches_by_variable[variable].append(float(value))\n",
    "                    matches_by_variable[f'{variable}_no_nans'].append(int(no_nans))\n",
    "                else:\n",
    "                    matches_by_variable[variable].append(np.nan)\n",
    "                    matches_by_variable[f'{variable}_no_nans'].append(np.nan)\n",
    "\n",
    "    return matches_by_variable\n",
    "\n",
    "\n",
    "# Function to remove outliers\n",
    "def remove_by_zscore(data : np.ndarray) -> np.ndarray:\n",
    "    z_scores = zscore(data)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "    data[abs_z_scores > 3] = np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "satellite_dates = []\n",
    "filenames = []\n",
    "# Load list of filenames to extract\n",
    "for filename in glob(r'D:\\NRT-Sentinel2\\outputs\\FRP_Lagoon\\section_1\\FRP\\*\\*.nc'):\n",
    "    date = datetime.datetime.strptime(os.path.basename(os.path.dirname(filename)).split('_')[0], '%Y%m%d')\n",
    "    satellite_dates.append(date)\n",
    "    filenames.append(filename)\n",
    "\n",
    "# Load In-Situ data\n",
    "in_situ = pd.read_excel(r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\Dados Historicos Lagoa_2025.xlsx')\n",
    "in_situ[['Latitude', 'Longitude', 'date']]\n",
    "\n",
    "# Compute nearest satellite images for each in-situ measurement\n",
    "nearest_satellite_dates = []\n",
    "nearest_satellite_diff = []\n",
    "nearest_filenames = []\n",
    "for date in in_situ.date:\n",
    "    diff = [abs(date - satellite_date) for satellite_date in satellite_dates]\n",
    "    nearest_satellite_dates.append(satellite_dates[np.argmin(diff)])\n",
    "    nearest_filenames.append(filenames[np.argmin(diff)])\n",
    "    nearest_satellite_diff.append(np.min(diff).days)\n",
    "\n",
    "nearest_satellite_dates, nearest_satellite_diff\n",
    "\n",
    "\n",
    "match_up_dates = {\n",
    "    'in_situ' : in_situ.date,\n",
    "    'satellite' : nearest_satellite_dates,\n",
    "    'filename' : nearest_filenames,\n",
    "    'diference' : nearest_satellite_diff,\n",
    "    'id' : in_situ.id,\n",
    "    'lon' : in_situ.Longitude,\n",
    "    'lat' : in_situ.Latitude\n",
    "}\n",
    "\n",
    "\n",
    "# Only use images with 2 days of difference\n",
    "match_up_dates_df = pd.DataFrame(match_up_dates)\n",
    "match_up_dates_df = match_up_dates_df[match_up_dates_df.diference <= 2]\n",
    "\n",
    "latlon_projection : str = 'epsg:4326'\n",
    "pseudo_mercator_projection : str = 'epsg:32722'\n",
    "transformer : Transformer = Transformer.from_crs(latlon_projection, pseudo_mercator_projection, always_xy = True)\n",
    "\n",
    "utm_x, utm_y = transformer.transform(match_up_dates_df.lon, match_up_dates_df.lat)\n",
    "\n",
    "points = np.array(list(zip(utm_x, utm_y)))\n",
    "variables =  ['chl_re_mishra', 'SPM_Nechad2016_665']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatchUp for Deep Water and Shallow Water - Only NDWI masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraxt variables data for each satellite image\n",
    "merged_df = pd.merge(left = match_up_dates_df, right = in_situ.loc[match_up_dates_df.index])\n",
    "for method_name, method in [('mean', np.nanmean), ('median', np.nanmedian)]:\n",
    "    data_by_variable = {}\n",
    "    results = []\n",
    "    for i in range(len(points)):\n",
    "        try:\n",
    "            res = match_points_mask_ndwi(match_up_dates_df.filename.iloc[i], variables, points[i:i+1], method = method)\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(res[variable][0])\n",
    "        except Exception as e:\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(np.nan)\n",
    "    df = pd.DataFrame(data_by_variable, index = match_up_dates_df.index)\n",
    "    df['id'] = match_up_dates_df['id']\n",
    "    merged_df = pd.merge(left = merged_df, right = df)\n",
    "\n",
    "\n",
    "out_folder = r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\results\\shallow_and_deep_water\\csv\\match_up'\n",
    "os.makedirs(out_folder, exist_ok = True)\n",
    "\n",
    "merged_df.to_excel(rf'{out_folder}\\Dados Historicos Lagoa_2025.xlsx', index = False)\n",
    "merged_df.to_csv(rf'{out_folder}\\Dados Historicos Lagoa_2025.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatchUp for Deep Water - Inverse of DeepWater Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraxt variables data for each satellite image\n",
    "merged_df = pd.merge(left = match_up_dates_df, right = in_situ.loc[match_up_dates_df.index])\n",
    "for method_name, method in [('mean', np.nanmean), ('median', np.nanmedian)]:\n",
    "    data_by_variable = {}\n",
    "    results = []\n",
    "    for i in range(len(points)):\n",
    "        try:\n",
    "            res = match_points_mask_ndwi_deepwater(match_up_dates_df.filename.iloc[i], variables, points[i:i+1], method = method, mask_deep = False)\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(res[variable][0])\n",
    "        except Exception as e:\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(np.nan)\n",
    "    df = pd.DataFrame(data_by_variable, index = match_up_dates_df.index)\n",
    "    df['id'] = match_up_dates_df['id']\n",
    "    merged_df = pd.merge(left = merged_df, right = df)\n",
    "\n",
    "\n",
    "out_folder = r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\results\\deep_water\\csv\\match_up'\n",
    "os.makedirs(out_folder, exist_ok = True)\n",
    "\n",
    "merged_df.to_excel(rf'{out_folder}\\Dados Historicos Lagoa_2025.xlsx', index = False)\n",
    "merged_df.to_csv(rf'{out_folder}\\Dados Historicos Lagoa_2025.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatchUp for Shallow Water - DeepWater Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraxt variables data for each satellite image\n",
    "merged_df = pd.merge(left = match_up_dates_df, right = in_situ.loc[match_up_dates_df.index])\n",
    "for method_name, method in [('mean', np.nanmean), ('median', np.nanmedian)]:\n",
    "    data_by_variable = {}\n",
    "    results = []\n",
    "    for i in range(len(points)):\n",
    "        try:\n",
    "            res = match_points_mask_ndwi_deepwater(match_up_dates_df.filename.iloc[i], variables, points[i:i+1], method = method, mask_deep = True)\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(res[variable][0])\n",
    "        except Exception as e:\n",
    "            for variable in variables:\n",
    "                data_by_variable.setdefault(f'{variable}_{method_name}', []).append(np.nan)\n",
    "    df = pd.DataFrame(data_by_variable, index = match_up_dates_df.index)\n",
    "    df['id'] = match_up_dates_df['id']\n",
    "    merged_df = pd.merge(left = merged_df, right = df)\n",
    "\n",
    "\n",
    "out_folder = r'D:\\sentinel2-acolite-prod\\jupyters\\Mar\\results\\shallow_water\\csv\\match_up'\n",
    "os.makedirs(out_folder, exist_ok = True)\n",
    "\n",
    "merged_df.to_excel(rf'{out_folder}\\Dados Historicos Lagoa_2025.xlsx', index = False)\n",
    "merged_df.to_csv(rf'{out_folder}\\Dados Historicos Lagoa_2025.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
